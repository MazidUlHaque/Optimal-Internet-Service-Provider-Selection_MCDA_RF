# -*- coding: utf-8 -*-
"""ISP_MCDA_RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h7om0ISeuJ2MTlYk-_Q1gqwa-mhzlTs5
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Load the data from the CSV file
data = pd.read_csv('data.csv')

# Mapping for 'Number of Devices'
device_mapping = {'More than 10 devices': 11}

# Mapping for 'How long you are using this connection from your current ISP?'
usage_mapping = {
    'Less than 1 year': 0,
    '1 to 2 years': 1,
    '2 to 3 years': 2,
    '3 to 4 years': 3,
    '4 to 5 years': 4,
    'More than 5 years': 5
}

# Mapping for 'How would you rate the technical support quality of your ISP?'
quality_mapping = {'Very poor': 1, 'Poor': 2, 'Fair': 3, 'Good': 4, 'Excellent': 5}

# Apply mappings to the respective columns
data['Number of Devices'] = data['Number of Devices'].apply(lambda x: device_mapping.get(x, x))
data['How long you are using this connection from your current ISP?'] = data['How long you are using this connection from your current ISP?'].apply(lambda x: usage_mapping.get(x, x))
data['How would you rate the technical support quality of your ISP?'] = data['How would you rate the technical support quality of your ISP?'].map(quality_mapping)

# Encode ISP names
encoded_isps = {}
for i, isp in enumerate(data['Internet Service Provider Name'].unique(), 1):
    encoded_isps[isp] = f'ISP{i}'
data['Internet Service Provider Name'] = data['Internet Service Provider Name'].map(encoded_isps)

# Save the preprocessed data to a new CSV file
data.to_csv('preprocessed_data.csv', index=False)

# Display the preprocessed data
print(data)

# Load the preprocessed data
data = pd.read_csv('preprocessed_data.csv')

# Define feature columns
feature_columns = ['Number of Devices', 'Average Downtime in Minutes', 'Cost in BDT', 'Internet Speed in Mbps', 'How long you are using this connection from your current ISP?']

# Impute missing values with the mean
imputer = SimpleImputer(strategy='mean')
data[feature_columns] = imputer.fit_transform(data[feature_columns])

# Define parameter grid for RandomForestRegressor
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize RandomForestRegressor
rf = RandomForestRegressor(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)

# Train the GridSearchCV
grid_search.fit(data[feature_columns], data['How would you rate the technical support quality of your ISP?'])

# Get the best RandomForestRegressor model from GridSearchCV
best_rf = grid_search.best_estimator_

# Get feature importances
feature_importances = best_rf.feature_importances_

# Normalize feature importances
normalized_importances = feature_importances / sum(feature_importances)

# Assign weights based on feature importances
weights = {feature: importance for feature, importance in zip(feature_columns, normalized_importances)}

# Apply weights to each criterion and calculate the overall score
data['Score'] = 0
for criterion, weight in weights.items():
    data['Score'] += data[criterion] * weight

# Get top ISPs based on the calculated score
top_isps = data.sort_values(by='Score', ascending=False).head(5)

# Display top ISPs with scores
print("Top ISPs based on multi-criteria decision analysis:")
for i, (isp, score) in enumerate(zip(top_isps['Internet Service Provider Name'], top_isps['Score']), 1):
    print(f"{i}. {isp} (Score: {score:.2f}")

# Predict ratings using the trained model
predictions = best_rf.predict(data[feature_columns])

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(data['How would you rate the technical support quality of your ISP?'], predictions)
print(f"Mean Squared Error (MSE): {mse:.2f}")

# Calculate R-squared
r2 = r2_score(data['How would you rate the technical support quality of your ISP?'], predictions)
print(f"R-squared: {r2:.2f}")

# Plot actual vs predicted ratings
plt.figure(figsize=(8, 6))
plt.scatter(data['How would you rate the technical support quality of your ISP?'], predictions, c=data['How would you rate the technical support quality of your ISP?'], cmap='viridis', alpha=0.5)
plt.colorbar(label='Actual Ratings')
plt.xlabel('Actual Ratings')
plt.ylabel('Predicted Ratings')
plt.title('Actual vs Predicted Ratings')
plt.show()

# Plot feature importances
plt.figure(figsize=(8, 6))
plt.barh(feature_columns, normalized_importances)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.show()